<!DOCTYPE html>
<html lang="en">
  <head>
    <title>
  Neural Networks and Deep Learning: Week 1 | Introduction to Deep Learning · Manuel Martinez
</title>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="Manuel Martinez">
<meta name="description" content="Introduction to Deep LearningLink to headingThis is the first course in Coursera&rsquo;s Deep Learning Specialization. I will try to summarize the major topics presented in each of the weeks of each course in a series of posts. The purpose of this is to both deepen my own understanding by explaining, but also for people who have not taken the specialization. Hopefully these posts will inspire you to do so.">
<meta name="keywords" content="blog,developer,personal">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Neural Networks and Deep Learning: Week 1 | Introduction to Deep Learning"/>
<meta name="twitter:description" content="Introduction to Deep LearningLink to headingThis is the first course in Coursera&rsquo;s Deep Learning Specialization. I will try to summarize the major topics presented in each of the weeks of each course in a series of posts. The purpose of this is to both deepen my own understanding by explaining, but also for people who have not taken the specialization. Hopefully these posts will inspire you to do so."/>

<meta property="og:title" content="Neural Networks and Deep Learning: Week 1 | Introduction to Deep Learning" />
<meta property="og:description" content="Introduction to Deep LearningLink to headingThis is the first course in Coursera&rsquo;s Deep Learning Specialization. I will try to summarize the major topics presented in each of the weeks of each course in a series of posts. The purpose of this is to both deepen my own understanding by explaining, but also for people who have not taken the specialization. Hopefully these posts will inspire you to do so." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://manmartgarc.github.io/posts/coursera/deep-learning-specialization/nn-dl/week1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-13T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-06-13T00:00:00+00:00" />





<link rel="canonical" href="https://manmartgarc.github.io/posts/coursera/deep-learning-specialization/nn-dl/week1/">


<link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.36f76aaf39a14ecf5c3a3c6250dcaf06c238b3d8365d17d646f95cb1874e852b.css" integrity="sha256-NvdqrzmhTs9cOjxiUNyvBsI4s9g2XRfWRvlcsYdOhSs=" crossorigin="anonymous" media="screen" />






  
    
    
    <link rel="stylesheet" href="/css/coder-dark.min.216e36d3eaf6f4cdfd67dc1200c49a8169e6478102977b3e9ac51a064c57054c.css" integrity="sha256-IW420&#43;r29M39Z9wSAMSagWnmR4ECl3s&#43;msUaBkxXBUw=" crossorigin="anonymous" media="screen" />
  



 




<link rel="icon" type="image/png" href="/images/favicon.ico" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon.ico" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">




<meta name="generator" content="Hugo 0.92.2" />





  </head>






<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      Manuel Martinez
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/posts/">Posts</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/projects/">Projects</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/cv/">CV</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="https://manmartgarc.github.io/posts/coursera/deep-learning-specialization/nn-dl/week1/">
              Neural Networks and Deep Learning: Week 1 | Introduction to Deep Learning
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime="2023-06-13T00:00:00Z">
                June 13, 2023
              </time>
            </span>
            <span class="reading-time">
              <i class="fa fa-clock-o" aria-hidden="true"></i>
              4-minute read
            </span>
          </div>
          
          <div class="categories">
  <i class="fa fa-folder" aria-hidden="true"></i>
    <a href="/categories/coursera/">Coursera</a>
      <span class="separator">•</span>
    <a href="/categories/deep-learning/">Deep Learning</a>
      <span class="separator">•</span>
    <a href="/categories/neural-networks-and-deep-learning/">Neural Networks and Deep Learning</a></div>

          <div class="tags">
  <i class="fa fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="/tags/machine-learning/">machine learning</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/deep-learning/">deep learning</a>
    </span></div>

        </div>
      </header>

      <div class="post-content">
        
        <h2 id="introduction-to-deep-learning">
  Introduction to Deep Learning
  <a class="heading-link" href="#introduction-to-deep-learning">
    <i class="fa fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>This is the first course in Coursera&rsquo;s <a href="https://www.coursera.org/specializations/deep-learning">Deep Learning Specialization</a>. I will try to summarize the major topics presented in each of the weeks of each course in a series of posts. The purpose of this is to both deepen my own understanding by explaining, but also for people who have not taken the specialization. Hopefully these posts will inspire you to do so.</p>
<p>This week&rsquo;s topics are:</p>
<ul>
<li><a href="#introduction-to-deep-learning">Introduction to Deep Learning</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
<hr>
<p>In the most basic sense, neural networks are a particular approach to machine learning, a process in which a computer learns to perform some task by analyzing training examples. They have their not so humble origins in people trying to understand and model the human brain, particularly the way in which humans learn and store information. Learning and information representation are one of the things that make deep learning powerful. But before we get to deep learning, we need to at least define learning.</p>
<p>Glossing over the definition for what learning is, let&rsquo;s say for now that learning amounts to being able to &ldquo;reconstruct&rdquo; some part of our data from the other parts (like supervised learning). Learning this reconstruction is what learning is within the context of machine learning.</p>
<p>So we said that neural networks are a particular approach to the machine learning problem. This approach uses a daisy-chain of building blocks called the <a href="https://en.wikipedia.org/wiki/Perceptron#:~:text=In%20the%20context%20of%20neural,a%20more%20complicated%20neural%20network">perceptron</a>. Think of the perceptron as a <em>single-layer neural network</em>.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> Deep neural networks have many such layers of perceptrons. Usually the input and output are called the input and output layers, while everything in between are called hidden layers.</p>
<figure><img src="/images/neural-net.png"
         alt="Simplified view of a feedforward artificial neural network"/><figcaption>
            <p><a href="https://en.wikipedia.org/wiki/Neural_network">Simplified view of a feedforward artificial neural network</a></p>
        </figcaption>
</figure>

<p>It turns out a single perceptron is not that flexible or generalizable, just like a single neuron is not that great at writing literature. However, and this is the important part, if you daisy-chain a bunch of them, and add some magic sauce (non-linearities) they are <em>extremely</em> generalizable. The magic of deep neural networks comes from the hidden layers. The hidden layers do something very important, which amounts to feature generation. For example if you have a dataset with some data, then the algorithm will learn how to combine the existing features into new features. And not just any features, but features that are relevant to learning the particular task. This is one of the key differences between deep learning and previous machine learning approaches. It does this by  <a href="https://en.wikipedia.org/wiki/Linear_combination#:~:text=In%20mathematics%2C%20a%20linear%20combination,a%20and%20b%20are%20constants">linearly combining</a> the outputs from previous layers, down the layers, until the output layer.</p>
<p>Going back to learning, generally there are two main paradigms for learning (and a couple of others):</p>
<ol>
<li><a href="https://en.wikipedia.org/wiki/Supervised_learning">Supervised Learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Unsupervised_learning">Unsupervised Learning</a></li>
</ol>
<p>At this point it&rsquo;s not terribly important to know the exact difference, other than two things. Supervised learning is so called because you use labeled data. Labeled data are pairs of features (covariates) and their associated label. Features could be the picture of a cat and the label is whether it&rsquo;s a cat or not, which is called classification. You could also predict the price of a house based on a house&rsquo;s features, and this is called regression. In either case explaining the performance of the algorithm is very straightforward: we are close/far from perfectly predicting (recombining) our target from the training samples. On the other hand, with unsupervised learning, there are no labels in the data, so you cannot objectively measure how the algorithm is doing based on labels. Unsupervised learning does use cost functions but they are not usually related to the labels in the data. These are commonly clustering or partitioning algorithms. The course focuses on supervised learning.</p>
<h2 id="summary">
  Summary
  <a class="heading-link" href="#summary">
    <i class="fa fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<ul>
<li>A neural network is a machine learning model that can combine the original features to make new ones relevant to the task.</li>
<li>There are different architectures of neural networks that work better in certain domains, such as convolutional neural networks (CNN) and recurrent neural networks (RNN).
<ul>
<li>CNNs are usually used in the field of computer vision.</li>
<li>RNNs are usually used with sequential data, such as audio or text.</li>
</ul>
</li>
<li>Supervised learning is when you have pairs of training samples and labels. The goal of a learning algorithm is to learn a mapping between $X$ the training samples and $Y$ the training labels.
<ul>
<li>Historically it&rsquo;s been easier to do supervised learning with structured data, such as a table of house listings. Unstructured data such as audio, images or text is harder and requires specialized architectures for the neural nets.</li>
<li>Bigger data, faster computation and better algorithms is driving deep learning across industry and research.</li>
</ul>
</li>
</ul>
<p>Next week&rsquo;s post is <a href="https://manmartgarc.github.io/posts/coursera/deep-learning-specialization/nn-dl/week2/">here</a>.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://en.wikipedia.org/wiki/Perceptron#:~:text=In%20the%20context%20of%20neural,a%20more%20complicated%20neural%20network.">Wikipedia | Perceptron</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

      </div>


      <footer>
        


        <div id="disqus_thread"></div>
<script>
  window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "https-manmartgarc-github-io" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
    
    document.addEventListener('themeChanged', function (e) { 
        if (document.readyState == 'complete') {
          DISQUS.reset({ reload: true, config: disqus_config });
        }
    });
</script>
        
        
      </footer>
    </article>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
    integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
    integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
    integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body,
      {
        delimiters: [
          {left: '$$', right: '$$', display:true},
          {left: '$', right: '$', display:false},
          {left: '\\(', right: '\\)', display: false},
          {left: '\\[', right: '\\]', display: true}
        ]
      }
    );"></script>
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
    2023
     Manuel Martinez 
    ·
    
      Licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA-4.0</a>
    ·
    
    Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
  </section>
</footer>

  </main>

  

  
  
  <script src="/js/coder.min.feb19891e099ae3b6acdd502ba6e51d722353e69bb0f9478ed80a05450af78d2.js" integrity="sha256-/rGYkeCZrjtqzdUCum5R1yI1Pmm7D5R47YCgVFCveNI="></script>
  

  

  

  

  

  

  

  

  

  
</body>

</html>
