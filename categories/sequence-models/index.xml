<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sequence Models on Manuel Martinez</title>
    <link>https://manmartgarc.github.io/categories/sequence-models/</link>
    <description>Recent content in Sequence Models on Manuel Martinez</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 13 Aug 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://manmartgarc.github.io/categories/sequence-models/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Sequence Models: Week 4 | Transformers</title>
      <link>https://manmartgarc.github.io/posts/coursera/deep-learning-specialization/sequence-models/week4/</link>
      <pubDate>Sun, 13 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://manmartgarc.github.io/posts/coursera/deep-learning-specialization/sequence-models/week4/</guid>
      <description>This is the fourth and last week of the fifth course of DeepLearning.AI&amp;rsquo;s Deep Learning Specialization offered on Coursera. The main topic for this week are transformers, a generalization of the attention model that has taken the deep learning world by storm since its inception in 2017.&#xA;This week&amp;rsquo;s topics are:&#xA;Transformer Network Intuition Self-Attention Multi-Head Attention Transformer Network Architecture More Information Transformer Network Intuition Link to heading We started with RNNs (known as part of the prehistoric era now), a simple model that reutilizes the same weights at each time steps; allowing to combine previous step&amp;rsquo;s hidden states with the current one.</description>
    </item>
    <item>
      <title>Sequence Models: Week 3 | Sequence Models &amp; Attention Mechanism</title>
      <link>https://manmartgarc.github.io/posts/coursera/deep-learning-specialization/sequence-models/week3/</link>
      <pubDate>Sat, 12 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://manmartgarc.github.io/posts/coursera/deep-learning-specialization/sequence-models/week3/</guid>
      <description>This is the third week of the fifth course of DeepLearning.AI&amp;rsquo;s Deep Learning Specialization offered on Coursera. This week goes over sequence-to-sequence models using beam search to optimize the classification step. We also go over the important concept of attention which generalizes a couple of things seen in the last week.&#xA;This week&amp;rsquo;s topics are:&#xA;Sequence to Sequence Architectures Basic Seq2Seq Models Picking the Most Likely Sentence Why not Greedy Search?</description>
    </item>
    <item>
      <title>Sequence Models: Week 2 | NLP &amp; Word Embeddings</title>
      <link>https://manmartgarc.github.io/posts/coursera/deep-learning-specialization/sequence-models/week2/</link>
      <pubDate>Thu, 10 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://manmartgarc.github.io/posts/coursera/deep-learning-specialization/sequence-models/week2/</guid>
      <description>This is the second week of the fifth course of DeepLearning.AI&amp;rsquo;s Deep Learning Specialization offered on Coursera. In this week we go over a little more in depth into natural language applications with sequence models, and also discuss word embeddings; an amazing technique for extracting semantic meaning from words.&#xA;This week&amp;rsquo;s topics are:&#xA;Introduction to Word Embeddings Word Representation Using Word Embeddings Properties of Word Embeddings Cosine Similarity Embedding Matrix Word Embeddings Learning Word Embeddings Word2Vec Negative Sampling GloVe Word Vectors Applications Using Word Embeddings Sentiment Classification De-biasing Word Embeddings Introduction to Word Embeddings Link to heading Word Representation Link to heading Word embeddings are a way of representing words.</description>
    </item>
    <item>
      <title>Sequence Models: Week 1 | Recurrent Neural Networks</title>
      <link>https://manmartgarc.github.io/posts/coursera/deep-learning-specialization/sequence-models/week1/</link>
      <pubDate>Tue, 08 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://manmartgarc.github.io/posts/coursera/deep-learning-specialization/sequence-models/week1/</guid>
      <description>This is the first week of the fifth course of DeepLearning.AI&amp;rsquo;s Deep Learning Specialization offered on Coursera. In this week we go over some motivation for sequence models. These are models that are designed to work with sequential data, otherwise known as time-series. Let&amp;rsquo;s get started.&#xA;This week&amp;rsquo;s topics are:&#xA;Why Sequence Models? Notation Representing Words Recurrent Neural Network Forward Propagation Different Types of RNNs Language Model and Sequence Generation Vanishing Gradients with RNNs Gated Recurrent Unit Long Short-Term Memory Bidirectional RNN Why Sequence Models?</description>
    </item>
  </channel>
</rss>
